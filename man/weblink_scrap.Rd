% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/weblink_scrap.R
\name{weblink_scrap}
\alias{weblink_scrap}
\title{Website web links scraping}
\usage{
weblink_scrap(link, contain = NULL, askRobot = FALSE)
}
\arguments{
\item{link}{the link of the web page to scrap}

\item{contain}{filter the web links according the character string provided. Particularly useful when extracting PDF or xlsx links (works also with regex)}

\item{askRobot}{logical. Should the function ask the robots.txt if we're allowed or not to scrap the web page ? Default is FALSE.}
}
\value{
a character vector.
}
\description{
This function is used to scrap web links from a website.
}
\examples{
\donttest{
# Extracting the web links within the World Bank research and publications page

link     <- "https://www.worldbank.org/en/research"

weblink_scrap(link)}

}
